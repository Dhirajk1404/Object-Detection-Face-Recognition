{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class YoloLayer(nn.Module):\n",
    "    def __init__(self, anchor_mask=[], num_classes=0, anchors=[], num_anchors=1):\n",
    "        super(YoloLayer, self).__init__()\n",
    "        self.anchor_mask = anchor_mask\n",
    "        self.num_classes = num_classes\n",
    "        self.anchors = anchors\n",
    "        self.num_anchors = num_anchors\n",
    "        self.anchor_step = len(anchors)/num_anchors\n",
    "        self.coord_scale = 1\n",
    "        self.noobject_scale = 1\n",
    "        self.object_scale = 5\n",
    "        self.class_scale = 1\n",
    "        self.thresh = 0.6\n",
    "        self.stride = 32\n",
    "        self.seen = 0\n",
    "\n",
    "    def forward(self, output, nms_thresh):\n",
    "        self.thresh = nms_thresh\n",
    "        masked_anchors = []\n",
    "            \n",
    "        for m in self.anchor_mask:\n",
    "            masked_anchors += self.anchors[m*self.anchor_step:(m+1)*self.anchor_step]\n",
    "                \n",
    "        masked_anchors = [anchor/self.stride for anchor in masked_anchors]\n",
    "        boxes = get_region_boxes(output.data, self.thresh, self.num_classes, masked_anchors, len(self.anchor_mask))\n",
    "            \n",
    "        return boxes\n",
    "\n",
    "    \n",
    "class Upsample(nn.Module):\n",
    "    def __init__(self, stride=2):\n",
    "        super(Upsample, self).__init__()\n",
    "        self.stride = stride\n",
    "    def forward(self, x):\n",
    "        stride = self.stride\n",
    "        assert(x.data.dim() == 4)\n",
    "        B = x.data.size(0)\n",
    "        C = x.data.size(1)\n",
    "        H = x.data.size(2)\n",
    "        W = x.data.size(3)\n",
    "        ws = stride\n",
    "        hs = stride\n",
    "        x = x.view(B, C, H, 1, W, 1).expand(B, C, H, stride, W, stride).contiguous().view(B, C, H*stride, W*stride)\n",
    "        return x\n",
    "\n",
    "\n",
    "#for route and shortcut\n",
    "class EmptyModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmptyModule, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "# support route shortcut\n",
    "class Darknet(nn.Module):\n",
    "    def __init__(self, cfgfile):\n",
    "        super(Darknet, self).__init__()\n",
    "        self.blocks = parse_cfg(cfgfile)\n",
    "        self.models = self.create_network(self.blocks) # merge conv, bn,leaky\n",
    "        self.loss = self.models[len(self.models)-1]\n",
    "\n",
    "        self.width = int(self.blocks[0]['width'])\n",
    "        self.height = int(self.blocks[0]['height'])\n",
    "\n",
    "        self.header = torch.IntTensor([0,0,0,0])\n",
    "        self.seen = 0\n",
    "\n",
    "    def forward(self, x, nms_thresh):            \n",
    "        ind = -2\n",
    "        self.loss = None\n",
    "        outputs = dict()\n",
    "        out_boxes = []\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            ind = ind + 1\n",
    "            if block['type'] == 'net':\n",
    "                continue\n",
    "            elif block['type'] in ['convolutional', 'upsample']: \n",
    "                x = self.models[ind](x)\n",
    "                outputs[ind] = x\n",
    "            elif block['type'] == 'route':\n",
    "                layers = block['layers'].split(',')\n",
    "                layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n",
    "                if len(layers) == 1:\n",
    "                    x = outputs[layers[0]]\n",
    "                    outputs[ind] = x\n",
    "                elif len(layers) == 2:\n",
    "                    x1 = outputs[layers[0]]\n",
    "                    x2 = outputs[layers[1]]\n",
    "                    x = torch.cat((x1,x2),1)\n",
    "                    outputs[ind] = x\n",
    "            elif block['type'] == 'shortcut':\n",
    "                from_layer = int(block['from'])\n",
    "                activation = block['activation']\n",
    "                from_layer = from_layer if from_layer > 0 else from_layer + ind\n",
    "                x1 = outputs[from_layer]\n",
    "                x2 = outputs[ind-1]\n",
    "                x  = x1 + x2\n",
    "                outputs[ind] = x\n",
    "            elif block['type'] == 'yolo':\n",
    "                boxes = self.models[ind](x, nms_thresh)\n",
    "                out_boxes.append(boxes)\n",
    "            else:\n",
    "                print('unknown type %s' % (block['type']))\n",
    "            \n",
    "        return out_boxes\n",
    "    \n",
    "\n",
    "    def print_network(self):\n",
    "        print_cfg(self.blocks)\n",
    "\n",
    "    def create_network(self, blocks):\n",
    "        models = nn.ModuleList()\n",
    "    \n",
    "        prev_filters = 3\n",
    "        out_filters =[]\n",
    "        prev_stride = 1\n",
    "        out_strides = []\n",
    "        conv_id = 0\n",
    "        for block in blocks:\n",
    "            if block['type'] == 'net':\n",
    "                prev_filters = int(block['channels'])\n",
    "                continue\n",
    "            elif block['type'] == 'convolutional':\n",
    "                conv_id = conv_id + 1\n",
    "                batch_normalize = int(block['batch_normalize'])\n",
    "                filters = int(block['filters'])\n",
    "                kernel_size = int(block['size'])\n",
    "                stride = int(block['stride'])\n",
    "                is_pad = int(block['pad'])\n",
    "                pad = (kernel_size-1)//2 if is_pad else 0\n",
    "                activation = block['activation']\n",
    "                model = nn.Sequential()\n",
    "                if batch_normalize:\n",
    "                    model.add_module('conv{0}'.format(conv_id), nn.Conv2d(prev_filters, filters, kernel_size, stride, pad, bias=False))\n",
    "                    model.add_module('bn{0}'.format(conv_id), nn.BatchNorm2d(filters))\n",
    "                else:\n",
    "                    model.add_module('conv{0}'.format(conv_id), nn.Conv2d(prev_filters, filters, kernel_size, stride, pad))\n",
    "                if activation == 'leaky':\n",
    "                    model.add_module('leaky{0}'.format(conv_id), nn.LeakyReLU(0.1, inplace=True))\n",
    "                prev_filters = filters\n",
    "                out_filters.append(prev_filters)\n",
    "                prev_stride = stride * prev_stride\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(model)\n",
    "            elif block['type'] == 'upsample':\n",
    "                stride = int(block['stride'])\n",
    "                out_filters.append(prev_filters)\n",
    "                prev_stride = prev_stride // stride\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(Upsample(stride))\n",
    "            elif block['type'] == 'route':\n",
    "                layers = block['layers'].split(',')\n",
    "                ind = len(models)\n",
    "                layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n",
    "                if len(layers) == 1:\n",
    "                    prev_filters = out_filters[layers[0]]\n",
    "                    prev_stride = out_strides[layers[0]]\n",
    "                elif len(layers) == 2:\n",
    "                    assert(layers[0] == ind - 1)\n",
    "                    prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\n",
    "                    prev_stride = out_strides[layers[0]]\n",
    "                out_filters.append(prev_filters)\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(EmptyModule())\n",
    "            elif block['type'] == 'shortcut':\n",
    "                ind = len(models)\n",
    "                prev_filters = out_filters[ind-1]\n",
    "                out_filters.append(prev_filters)\n",
    "                prev_stride = out_strides[ind-1]\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(EmptyModule())\n",
    "            elif block['type'] == 'yolo':\n",
    "                yolo_layer = YoloLayer()\n",
    "                anchors = block['anchors'].split(',')\n",
    "                anchor_mask = block['mask'].split(',')\n",
    "                yolo_layer.anchor_mask = [int(i) for i in anchor_mask]\n",
    "                yolo_layer.anchors = [float(i) for i in anchors]\n",
    "                yolo_layer.num_classes = int(block['classes'])\n",
    "                yolo_layer.num_anchors = int(block['num'])\n",
    "                yolo_layer.anchor_step = len(yolo_layer.anchors)//yolo_layer.num_anchors\n",
    "                yolo_layer.stride = prev_stride\n",
    "                out_filters.append(prev_filters)\n",
    "                out_strides.append(prev_stride)\n",
    "                models.append(yolo_layer)\n",
    "            else:\n",
    "                print('unknown type %s' % (block['type']))\n",
    "    \n",
    "        return models\n",
    "\n",
    "    def load_weights(self, weightfile):\n",
    "        print()\n",
    "        fp = open(weightfile, 'rb')\n",
    "        header = np.fromfile(fp, count=5, dtype=np.int32)\n",
    "        self.header = torch.from_numpy(header)\n",
    "        self.seen = self.header[3]\n",
    "        buf = np.fromfile(fp, dtype = np.float32)\n",
    "        fp.close()\n",
    "\n",
    "        start = 0\n",
    "        ind = -2\n",
    "        counter = 3\n",
    "        for block in self.blocks:\n",
    "            if start >= buf.size:\n",
    "                break\n",
    "            ind = ind + 1\n",
    "            if block['type'] == 'net':\n",
    "                continue\n",
    "            elif block['type'] == 'convolutional':\n",
    "                model = self.models[ind]\n",
    "                batch_normalize = int(block['batch_normalize'])\n",
    "                if batch_normalize:\n",
    "                    start = load_conv_bn(buf, start, model[0], model[1])\n",
    "                else:\n",
    "                    start = load_conv(buf, start, model[0])\n",
    "            elif block['type'] == 'upsample':\n",
    "                pass\n",
    "            elif block['type'] == 'route':\n",
    "                pass\n",
    "            elif block['type'] == 'shortcut':\n",
    "                pass\n",
    "            elif block['type'] == 'yolo':\n",
    "                pass\n",
    "            else:\n",
    "                print('unknown type %s' % (block['type']))\n",
    "            \n",
    "            percent_comp = (counter / len(self.blocks)) * 100\n",
    "\n",
    "            print('Loading weights. Please Wait...{:.2f}% Complete'.format(percent_comp), end = '\\r', flush = True)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            \n",
    "            \n",
    "def convert2cpu(gpu_matrix):\n",
    "    return torch.FloatTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
    "\n",
    "\n",
    "def convert2cpu_long(gpu_matrix):\n",
    "    return torch.LongTensor(gpu_matrix.size()).copy_(gpu_matrix)\n",
    "\n",
    "\n",
    "def get_region_boxes(output, conf_thresh, num_classes, anchors, num_anchors, only_objectness = 1, validation = False):\n",
    "    anchor_step = len(anchors)//num_anchors\n",
    "    if output.dim() == 3:\n",
    "        output = output.unsqueeze(0)\n",
    "    batch = output.size(0)\n",
    "    assert(output.size(1) == (5+num_classes)*num_anchors)\n",
    "    h = output.size(2)\n",
    "    w = output.size(3)\n",
    "\n",
    "    all_boxes = []\n",
    "    output = output.view(batch*num_anchors, 5+num_classes, h*w).transpose(0,1).contiguous().view(5+num_classes, batch*num_anchors*h*w)\n",
    "\n",
    "    grid_x = torch.linspace(0, w-1, w).repeat(h,1).repeat(batch*num_anchors, 1, 1).view(batch*num_anchors*h*w).type_as(output) #cuda()\n",
    "    grid_y = torch.linspace(0, h-1, h).repeat(w,1).t().repeat(batch*num_anchors, 1, 1).view(batch*num_anchors*h*w).type_as(output) #cuda()\n",
    "    xs = torch.sigmoid(output[0]) + grid_x\n",
    "    ys = torch.sigmoid(output[1]) + grid_y\n",
    "\n",
    "    anchor_w = torch.Tensor(anchors).view(num_anchors, anchor_step).index_select(1, torch.LongTensor([0]))\n",
    "    anchor_h = torch.Tensor(anchors).view(num_anchors, anchor_step).index_select(1, torch.LongTensor([1]))\n",
    "    anchor_w = anchor_w.repeat(batch, 1).repeat(1, 1, h*w).view(batch*num_anchors*h*w).type_as(output) #cuda()\n",
    "    anchor_h = anchor_h.repeat(batch, 1).repeat(1, 1, h*w).view(batch*num_anchors*h*w).type_as(output) #cuda()\n",
    "    ws = torch.exp(output[2]) * anchor_w\n",
    "    hs = torch.exp(output[3]) * anchor_h\n",
    "\n",
    "    det_confs = torch.sigmoid(output[4])\n",
    "    cls_confs = torch.nn.Softmax(dim=1)(output[5:5+num_classes].transpose(0,1)).detach()\n",
    "    cls_max_confs, cls_max_ids = torch.max(cls_confs, 1)\n",
    "    cls_max_confs = cls_max_confs.view(-1)\n",
    "    cls_max_ids = cls_max_ids.view(-1)\n",
    "\n",
    "    \n",
    "    sz_hw = h*w\n",
    "    sz_hwa = sz_hw*num_anchors\n",
    "    det_confs = convert2cpu(det_confs)\n",
    "    cls_max_confs = convert2cpu(cls_max_confs)\n",
    "    cls_max_ids = convert2cpu_long(cls_max_ids)\n",
    "    xs = convert2cpu(xs)\n",
    "    ys = convert2cpu(ys)\n",
    "    ws = convert2cpu(ws)\n",
    "    hs = convert2cpu(hs)\n",
    "    if validation:\n",
    "        cls_confs = convert2cpu(cls_confs.view(-1, num_classes))\n",
    "\n",
    "    for b in range(batch):\n",
    "        boxes = []\n",
    "        for cy in range(h):\n",
    "            for cx in range(w):\n",
    "                for i in range(num_anchors):\n",
    "                    ind = b*sz_hwa + i*sz_hw + cy*w + cx\n",
    "                    det_conf =  det_confs[ind]\n",
    "                    if only_objectness:\n",
    "                        conf =  det_confs[ind]\n",
    "                    else:\n",
    "                        conf = det_confs[ind] * cls_max_confs[ind]\n",
    "    \n",
    "                    if conf > conf_thresh:\n",
    "                        bcx = xs[ind]\n",
    "                        bcy = ys[ind]\n",
    "                        bw = ws[ind]\n",
    "                        bh = hs[ind]\n",
    "                        cls_max_conf = cls_max_confs[ind]\n",
    "                        cls_max_id = cls_max_ids[ind]\n",
    "                        box = [bcx/w, bcy/h, bw/w, bh/h, det_conf, cls_max_conf, cls_max_id]\n",
    "                        if (not only_objectness) and validation:\n",
    "                            for c in range(num_classes):\n",
    "                                tmp_conf = cls_confs[ind][c]\n",
    "                                if c != cls_max_id and det_confs[ind]*tmp_conf > conf_thresh:\n",
    "                                    box.append(tmp_conf)\n",
    "                                    box.append(c)\n",
    "                        boxes.append(box)\n",
    "        all_boxes.append(boxes)\n",
    "\n",
    "    return all_boxes\n",
    "\n",
    "\n",
    "def parse_cfg(cfgfile):\n",
    "    blocks = []\n",
    "    fp = open(cfgfile, 'r')\n",
    "    block =  None\n",
    "    line = fp.readline()\n",
    "    while line != '':\n",
    "        line = line.rstrip()\n",
    "        if line == '' or line[0] == '#':\n",
    "            line = fp.readline()\n",
    "            continue        \n",
    "        elif line[0] == '[':\n",
    "            if block:\n",
    "                blocks.append(block)\n",
    "            block = dict()\n",
    "            block['type'] = line.lstrip('[').rstrip(']')\n",
    "            # set default value\n",
    "            if block['type'] == 'convolutional':\n",
    "                block['batch_normalize'] = 0\n",
    "        else:\n",
    "            key,value = line.split('=')\n",
    "            key = key.strip()\n",
    "            if key == 'type':\n",
    "                key = '_type'\n",
    "            value = value.strip()\n",
    "            block[key] = value\n",
    "        line = fp.readline()\n",
    "\n",
    "    if block:\n",
    "        blocks.append(block)\n",
    "    fp.close()\n",
    "    return blocks\n",
    "\n",
    "\n",
    "def print_cfg(blocks):\n",
    "    print('layer     filters    size              input                output');\n",
    "    prev_width = 416\n",
    "    prev_height = 416\n",
    "    prev_filters = 3\n",
    "    out_filters =[]\n",
    "    out_widths =[]\n",
    "    out_heights =[]\n",
    "    ind = -2\n",
    "    for block in blocks:\n",
    "        ind = ind + 1\n",
    "        if block['type'] == 'net':\n",
    "            prev_width = int(block['width'])\n",
    "            prev_height = int(block['height'])\n",
    "            continue\n",
    "        elif block['type'] == 'convolutional':\n",
    "            filters = int(block['filters'])\n",
    "            kernel_size = int(block['size'])\n",
    "            stride = int(block['stride'])\n",
    "            is_pad = int(block['pad'])\n",
    "            pad = (kernel_size-1)//2 if is_pad else 0\n",
    "            width = (prev_width + 2*pad - kernel_size)//stride + 1\n",
    "            height = (prev_height + 2*pad - kernel_size)//stride + 1\n",
    "            print('%5d %-6s %4d  %d x %d / %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'conv', filters, kernel_size, kernel_size, stride, prev_width, prev_height, prev_filters, width, height, filters))\n",
    "            prev_width = width\n",
    "            prev_height = height\n",
    "            prev_filters = filters\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'upsample':\n",
    "            stride = int(block['stride'])\n",
    "            filters = prev_filters\n",
    "            width = prev_width*stride\n",
    "            height = prev_height*stride\n",
    "            print('%5d %-6s           * %d   %3d x %3d x%4d   ->   %3d x %3d x%4d' % (ind, 'upsample', stride, prev_width, prev_height, prev_filters, width, height, filters))\n",
    "            prev_width = width\n",
    "            prev_height = height\n",
    "            prev_filters = filters\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'route':\n",
    "            layers = block['layers'].split(',')\n",
    "            layers = [int(i) if int(i) > 0 else int(i)+ind for i in layers]\n",
    "            if len(layers) == 1:\n",
    "                print('%5d %-6s %d' % (ind, 'route', layers[0]))\n",
    "                prev_width = out_widths[layers[0]]\n",
    "                prev_height = out_heights[layers[0]]\n",
    "                prev_filters = out_filters[layers[0]]\n",
    "            elif len(layers) == 2:\n",
    "                print('%5d %-6s %d %d' % (ind, 'route', layers[0], layers[1]))\n",
    "                prev_width = out_widths[layers[0]]\n",
    "                prev_height = out_heights[layers[0]]\n",
    "                assert(prev_width == out_widths[layers[1]])\n",
    "                assert(prev_height == out_heights[layers[1]])\n",
    "                prev_filters = out_filters[layers[0]] + out_filters[layers[1]]\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] in ['region', 'yolo']:\n",
    "            print('%5d %-6s' % (ind, 'detection'))\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        elif block['type'] == 'shortcut':\n",
    "            from_id = int(block['from'])\n",
    "            from_id = from_id if from_id > 0 else from_id+ind\n",
    "            print('%5d %-6s %d' % (ind, 'shortcut', from_id))\n",
    "            prev_width = out_widths[from_id]\n",
    "            prev_height = out_heights[from_id]\n",
    "            prev_filters = out_filters[from_id]\n",
    "            out_widths.append(prev_width)\n",
    "            out_heights.append(prev_height)\n",
    "            out_filters.append(prev_filters)\n",
    "        else:\n",
    "            print('unknown type %s' % (block['type']))\n",
    "\n",
    "            \n",
    "def load_conv(buf, start, conv_model):\n",
    "    num_w = conv_model.weight.numel()\n",
    "    num_b = conv_model.bias.numel()\n",
    "    conv_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
    "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w]).view_as(conv_model.weight.data)); start = start + num_w\n",
    "    return start\n",
    "\n",
    "\n",
    "def load_conv_bn(buf, start, conv_model, bn_model):\n",
    "    num_w = conv_model.weight.numel()\n",
    "    num_b = bn_model.bias.numel()\n",
    "    bn_model.bias.data.copy_(torch.from_numpy(buf[start:start+num_b]));     start = start + num_b\n",
    "    bn_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
    "    bn_model.running_mean.copy_(torch.from_numpy(buf[start:start+num_b]));  start = start + num_b\n",
    "    bn_model.running_var.copy_(torch.from_numpy(buf[start:start+num_b]));   start = start + num_b\n",
    "    conv_model.weight.data.copy_(torch.from_numpy(buf[start:start+num_w]).view_as(conv_model.weight.data)); start = start + num_w\n",
    "    return start\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
